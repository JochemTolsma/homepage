---
title: Consequences of Egocentric Networks (methods)
author: JochemTolsma
date: '2020-09-07'
slug: dyads4
categories:
  - R
  - Social Networks
tags: []
linktitle: Egonets-Consequences-Methods

summary: "micro-macro model, tutorial, R, Lavaan"
lastmod: '2020-08-19T08:27:34+02:00'

type: book
weight: 40

 
output:
  blogdown::html_page:
    highlight: "haddock"
    number_sections: yes
    self_contained: no
    toc: true
    fig_width: 6
    dev: "svg"

---


<!--set global settings--> 
```{r, globalsettings, echo=FALSE, warning=FALSE}
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=100),tidy=TRUE, warning = FALSE, message = FALSE, cache=TRUE, attr.source = ".numberLines", class.source="highlightt")
options(width = 100)
```


<!--copy to clipboard-->
```{r klippy, echo=FALSE, include=TRUE}
require(klippy)
klippy::klippy()
klippy::klippy(position = c('top', 'left'))
#klippy::klippy(color = 'darkred')
#klippy::klippy(tooltip_message = 'Click to copy', tooltip_success = 'Done')
```
<!---
https://www.w3schools.com/w3css/w3css_buttons.asp
https://www.freecodecamp.org/news/a-quick-guide-to-styling-buttons-using-css-f64d4f96337f/
--->

<button onclick="window.location.href='static/index.Rmd';">download code</button>


![](static/micro-macro1.png)  

**Figure:** Basic micro-macro model



# Introduction

In this assignment/tutorial I will demonstrate how to estimate a micro-macro model with the R package [Lavaan](https://cran.r-project.org/package=lavaan). The Lavaan website can be found [here](https://www.lavaan.ugent.be/). During the workgroup I will explain all code. For those of you who don't attend the workgroups, google knows way more than I do. 

{{% alert warning %}}
In the upper left and right corner of the code blocks you will find copy-to-clipboard buttons. Use these buttons to copy the code to your own editor. 
{{% /alert %}}


# Before you start

Before you start, check whether you run the latest RStudio version (from the Help menu, pick 'check for updates' and whether you need to update R. 

```{r update, eval=FALSE}
install.packages("installr")  #you  first install packages
require(installr)  #then you will need to activate packages. 
updateR() #run the function to start the update process
```


Give your script a nice name. Include the author, and data when you last modified the script. Include a lot of comments in your script! Don't forget, always start with cleaning up your workspace. 

```{r cleanup}
###Author: JOCHEM TOLSMA###
###Lastmod: 31-08-2020###

#cleanup workspace
rm (list = ls( )) 
```

And set your working directory. 
```{r setwd, eval=FALSE}
#set working directory
setwd("C:\\YOURDIR\\YOURSUBDIR\\YOURSUBSUBDIR\\")  #change to your own workdirectory
```

Install the packages you will need. 

```{r packages, eval=FALSE}
#install packages
install.packages("lavaan", dependencies=TRUE) # to estimate the micro-macro model
install.packages("psych") # to describe our dataset
install.packages("nlme") # for the multilevel models
```



# Data 

## Simulate data

If I try to get an understanding of a new method, I usually use a simulated dataset. Then I at least know what the world looks like (I know what I have put in so I know what I should get out of the model). For you guys and gals, it is not necessary to understand the simulation process but feel free to have a close look. 


```{r,  attr.source = '.numberLines', results='hold'}
set.seed(13789876)
#simulate the true network characteristic
LX <- rnorm(1000, 0, 2)
#this network characteristic is latent, not measured. We have six indicators for this latent variable: 2 per alter; 3 alters.  

#a good indicator
x1 <- alt1_xa <- LX + rnorm(1000, 0, 1)
x2 <- alt2_xa <- LX + rnorm(1000, 0, 1)
x3 <- alt3_xa <- LX + rnorm(1000, 0, 1)

#a messy indicator
alt1_xb <- .3*LX + 0.1*x1 +  rnorm(1000, 0, 1) + 0.1*x1*rnorm(1000, 0, 1)
alt2_xb <- .3*LX + 0.1*x2 + rnorm(1000, 0, 1)  + 0.1*x3*rnorm(1000, 0, 1)
alt3_xb <- .3*LX + 0.1*x3 + rnorm(1000, 0, 1)  + 0.1*x3*rnorm(1000, 0, 1)

#we also have missingness (MCAR)
n1 <- rbinom(1000, 1,.95)
n2 <- rbinom(1000, 1,.85)
n3 <- rbinom(1000, 1,.75)

alt1_xa <- ifelse(n1, alt1_xa, NA)
alt2_xa <- ifelse(n2, alt2_xa, NA)
alt3_xa <- ifelse(n3, alt3_xa, NA)

alt1_xb <- ifelse(n1, alt1_xb, NA)
alt2_xb <- ifelse(n2, alt2_xb, NA)
alt3_xb <- ifelse(n3, alt3_xb, NA)

#lets calculate network size. 
ns <- rowSums(cbind(n1,n2,n3))

#simulate two dependnt variables to play with. 
# mean alter effect
Y1 <- 5*LX + rnorm(1000, 0, 5)

#total alter effect
Y2 <- 3*LX*ns + rnorm(1000, 0, 5)

ID <- 1:length(Y1)


data_wide <- data.frame(ID, Y1, Y2, alt1_xa, alt2_xa, alt3_xa, alt1_xb,alt2_xb,alt3_xb)

data_long <- reshape(data_wide, direction='long', 
        varying=c('alt1_xa', 'alt1_xb' ,'alt2_xa', 'alt2_xb', 'alt3_xa','alt3_xb'), 
        timevar='alter',
        v.names=c('xa', 'xb'),
        times=c('alt1', 'alt2', 'alt3'),
        idvar='ID')



```


We have a dataset with two different dependent variables: **Y1** and **Y2**. For each ego we collected information on at least 3 alters. For each alter we have information on two characteristics: **xa** and **xb**. Suppose these alter characteristics are indicators of alter's happiness. We want to know if alter's happiness is related to ego's happiness. 
O yeah, we have our data in both long and wide format. 
 
## have a look at your data  
>**Assingment 1:** Have a look at your data. What are the percentages of missing data?  
>**Assingment 2:** Try to make your own dataset in long format from the dataset in wide format.  


# Naive approaches 

## just try to use one indicator of one alter? 

This would imply estimating a simple linear OLS model. 

```{r,  attr.source = '.numberLines', results='hold'}
#using one alter observation
summary(lm(Y1 ~ alt1_xa, data=data_wide))

```

## Aggregation method

But obviously we would like to use the information on all alters. 
One method is to use an aggregation method. Thus calculate the mean happiness score of the alters and use to predict ego's happiness. It is called the aggregation method because we now have one observation per egonet.   

>**Assingment 3:** Before you look at the code below. Try to calculate the mean happiness score of the alters. Be aware that we missing values in our dataset. 

```{r,  attr.source = '.numberLines', results='hold'}
#aggregation
#first calculate the mean score of the alters. 


data_wide$xam <- rowMeans(cbind(data_wide$alt1_xa,data_wide$alt2_xa,data_wide$alt3_xa ), na.rm=TRUE)
summary(lm(Y1 ~ xam, data=data_wide))
```
## Disaggregation method

Another common approach is to disaggregate the data. In this approach we match the score of ego to all individual alters. 


```{r,  attr.source = '.numberLines', results='hold'}

summary(lm(Y1 ~ xa, data=data_long))
```
# micro-macro approach

Both approaches do not do justice to the structure of our dataset. We have information on alters (lowest level / alter-level / micro-level) and these determine an egonet characteristic (highest level / ego-level / macro-level). Where in the traditional multi-level model we use macro-level variables to predict micro-level variables, we now have micro-level variables predicting macro-level variables. See Figure below.

![](static/micro-macro1.png)
**Figure:** Micro-macro latent variable model with one micro-level variable[^1]

[^1]: Images adapted from: Bennink, M., Croon, M. A., Kroon, B., & Vermunt, J. K. (2016). Micro–macro multilevel latent class models with multiple discrete individual-level variables. *Advances in Data Analysis and Classification, 10*(2), 139-154.

In the literature two approaches are discussed to estimate a micro-macro model, a persons as variables approach and a multi-level approach. The persons as variables approach is - I hope - easiest to implement. The idea is that the alter scores load on a latent variable at the ego-level. This latent variable has a random component at the ego-level (cf random intercept in multi-level models). In a basic model, the latent variable is the (biased corrected) mean alter-score.   
I am using the package Lavaan to estimate the models. In the section 'alternative approaches' I will demonstrate the multi-level approach and the syntax to estimate these models with MPlus (within R). 

## first quickly estimate the previous models in Lavaan. 

Information of one alter only: 
```{r,  attr.source = '.numberLines', results='hold'}
library(lavaan)
model1 <- '
  Y1 ~ alt1_xa
  Y1 ~ 1
  Y1 ~~ Y1
  '

fit1 <- lavaan(model1, data = data_wide)
summary(fit1)

```
Aggregation method: 

```{r,  attr.source = '.numberLines', results='hold'}
library(lavaan)
model1 <- '
  Y1 ~ xam
  Y1 ~ 1
  Y1 ~~ Y1
  '

fit1 <- lavaan(model1, data = data_wide)
summary(fit1)


```
Disaggregation method: 
```{r,  attr.source = '.numberLines', results='hold'}
library(lavaan)
model1 <- '
  Y1 ~ xa
  Y1 ~ 1
  Y1 ~~ Y1
  '

fit1 <- lavaan(model1, data = data_long)
summary(fit1)

```
## Persons as variable approach in Lavaan

The assumption is that the alters are indistinguishable. Thus variables of alters have presumably the same mean-value, same-variance, same loading on the latent variable. 

>**Assignment 4:** Test some of these assumptions. 

We work with a latent variable. Hence we have to either fix the variance of the latent-variable or fix the factor loading of one of our indicator variables. I have chosen for the latter. I fixed the loading to "1". But given the assumptions just mentioned above, all of them are fixed. The advantage is that one unit increase in e.g. `alt1_xa` leads to one unit increase in our latent variable `FX`. We hence are able to compare the estimate of the latent variable with the previous estimates we obtained for the alter characteristics. Note, we do not include an exogenous variable at the ego-level yet.   

### persons as variables, cases listwise deleted

```{r ,  attr.source = '.numberLines', results='hold'}
#one individual-level predictor, one latent variable at group level
model2 <- '
  
  FX =~ 1*alt1_xa
  FX =~ 1*alt2_xa
  FX =~ 1*alt3_xa
  
  alt1_xa ~~ a*alt1_xa
  alt2_xa ~~ a*alt2_xa
  alt3_xa ~~ a*alt3_xa
  FX ~~ FX
  Y1 ~~ Y1
  
  Y1 ~ FX
  Y1 ~ 1
  alt1_xa ~ c*1
  alt2_xa ~ c*1
  alt3_xa ~ c*1
'

fit <- lavaan(model2, data = data_wide)
summary(fit)


```

### persons as variables, include cases with missing values on alter-characterstics

A big advantage of the micro-macro model is that we do not have to delete cases in a listwise manner. The above estimates are based on respondents who reported to have 3 alters. But naturally, not everyone will have a complete network of 3 alters. Thus, lets tell Lavaan to include those cases as well. 


```{r ,  attr.source = '.numberLines', results='hold'}
#one individual-level predictor, one latent variable at group level
model2 <- '
  
  FX =~ 1*alt1_xa
  FX =~ 1*alt2_xa
  FX =~ 1*alt3_xa
  
  alt1_xa ~~ a*alt1_xa
  alt2_xa ~~ a*alt2_xa
  alt3_xa ~~ a*alt3_xa
  FX ~~ FX
  Y1 ~~ Y1
  
  Y1 ~ FX 
  Y1 ~ 1
  alt1_xa ~ c*1
  alt2_xa ~ c*1
  alt3_xa ~ c*1
'

fit <- lavaan(model2, data = data_wide, missing = "fiml", fixed.x=FALSE)
summary(fit)


```

And there you have it. 

# Assignment

> **Assignment 5:** Re-estimate the micro-macro model but now use the other indicator.  

![](static/micro-macro2.png) 
**Figure:** Micro-macro latent variable model with two micro-level variables

> **Assignment 6:** Re-estimate the micro-macro model but now use both indicators. See the figure above for the intended model. Note, we do not have an exogenous variable at the ego-level yet. We include a covariance between the two indicators at the alter-level, because it may not be reasonable to assume that all of the association between the alter-level indicators is explained by the latent-variable. 

![](static/micro-macro3.png) 
**Figure:** Micro-macro latent variable model with two micro-level variables. Ego-level variable X moderates the impact of the latent variable at the group-level.   

{{% alert warning %}}  
Assignment 7 is way too difficult. First, in Lavaan it is not straightforward to estimate interaction effects when the interaction variable involves a latent-variable. Second, the variable size is not normally distributed. This violation of model assumptions leads to all kind of 'problems'. 
{{% / alert  %}}  

> **Assignment 7:** Test the hypothesis that the larger the core-discussion network, the smaller the influence of each individual alter will be. Test this hypothesis for both dependent variables. Bonus: estimate both dependent variables in one SEM. See the figure above for the intended model.   

> **Assignment 8:** Please now use a real dataset. Formulate an interesting hypothesis (and provide a motivation) on how the CDN (i.e. how alters) may influence the "Attitude towards eu-integration" of ego.  

# Real data

Download data [here](static/sn2021_egonetdata_v2.Rdata).   
  
Save it in your working directory 

If you want to use this data run the following command `load('sn2021_egonetdata_v2.Rdata')`

{{% alert note %}}

**Description of dataset**  
Subset of the LISS panel data (year 2009 and 2010).  
Four ego variables (eu, educ, age, g).  
Three confidant variables (educ_a, age_a, g_a).  
In the wide data the first number in the label of confidant variables indicates the survey wave, the second number the alter id. For this assignment please use data in wide format. 

liss_wide: liss data in a wide dataframe. 
liss_long: liss data in a long dataframe.


Dependent variables:  
**'eu'** Attitude towards eu-integration (0 "EU integration went to far" to 4 "EU integration not far enough")

Ego control variables:  
**'educ'** is educational attainment of ego in years.  
**'age'** is the self-reported age of respondents.  
**'g'** measures whether respondents are female (1) or male(0).  
 
Alter variables:  
**'educ_a'** measures the educational attainment of confidant in years.
**'g_a'** measures the gender of confidants, female (1) or male (0).  
**'age_a'** measures the age of confidants in 14 categories. These are 
1 younger than 16
2 16 - 20
3 21 - 25
4 26 - 30
5 31 - 35
6 36 - 40
7 41 - 45
8 46 - 50
9 51 - 55
10 56 - 60
11 61 - 65
12 66 - 70
13 71 years or older

{{% /alert %}}

# answers

## calculate network size

```{r}
data_wide$size <- as.numeric(rowSums(!is.na(cbind(data_wide$alt1_xa, data_wide$alt2_xa, data_wide$alt3_xa))))
table(data_wide$size, useNA="always")
                                 
```

## Assignment 6

I also included the main effect of size. 
Please note that size is not a normally distributed variable. This may lead to all kind of estimation problems. 
See [here]("http://www.understandingdata.net/2017/03/22/cfa-in-lavaan/") and [here]("https://lavaan.ugent.be/tutorial/cat.html").

```{r,  attr.source = '.numberLines', results='hold'}
#just ignore the non-normality of size
model <- '
  #latent variable
  FX =~ 1*alt1_xa
  FX =~ 1*alt2_xa
  FX =~ 1*alt3_xa
  
  FX =~ a*alt1_xb
  FX =~ a*alt2_xb
  FX =~ a*alt3_xb
  
  #variances
  alt1_xa ~~ b*alt1_xa
  alt2_xa ~~ b*alt2_xa
  alt3_xa ~~ b*alt3_xa
  
  alt1_xb ~~ c*alt1_xb
  alt2_xb ~~ c*alt2_xb
  alt3_xb ~~ c*alt3_xb
  
  FX ~~ FX
  Y1 ~~ Y1
  Y2 ~~ Y2
  size ~~ size
  
  #covariances
  Y1 ~~ Y2
  alt1_xa ~~ d*alt1_xb
  alt2_xa ~~ d*alt2_xb
  alt3_xa ~~ d*alt3_xb
  
  #regression model
  Y1 ~ FX + size
  Y1 ~ 1
  FX ~ size
  Y2 ~ FX + size
  Y2 ~ 1
   
  
  #intercepts/means
  alt1_xa ~ e*1
  alt2_xa ~ e*1
  alt3_xa ~ e*1
  alt1_xb ~ f*1
  alt2_xb ~ f*1
  alt3_xb ~ f*1
  
'


fit1 <- lavaan(model, data = data_wide, missing = "fiml", fixed.x=FALSE)

#declare the size variable to be ordered. We do have to switch of estimation procedure. 
data_wide$size2 <- ordered(data_wide$size)

# The code below won't work because if we delete observations with missing values, we don't have any variance left in the size variable. A solution would be to use a two-step approach. 
# model <- '
#   #latent variable
#   FX =~ 1*alt1_xa
#   FX =~ 1*alt2_xa
#   FX =~ 1*alt3_xa
#   
#   FX =~ a*alt1_xb
#   FX =~ a*alt2_xb
#   FX =~ a*alt3_xb
#   
#   #variances
#   alt1_xa ~~ b*alt1_xa
#   alt2_xa ~~ b*alt2_xa
#   alt3_xa ~~ b*alt3_xa
#   
#   alt1_xb ~~ c*alt1_xb
#   alt2_xb ~~ c*alt2_xb
#   alt3_xb ~~ c*alt3_xb
#   
#   FX ~~ FX
#   Y1 ~~ Y1
#   Y2 ~~ Y2
#   size2 ~~ size2
#   
#   #covariances
#   Y1 ~~ Y2
#   alt1_xa ~~ d*alt1_xb
#   alt2_xa ~~ d*alt2_xb
#   alt3_xa ~~ d*alt3_xb
#   
#   #regression model
#   Y1 ~ FX + size2
#   Y1 ~ 1
#   FX ~ size2
#   Y2 ~ FX + size2
#   Y2 ~ 1
#    
#   
#   #intercepts/means
#   alt1_xa ~ e*1
#   alt2_xa ~ e*1
#   alt3_xa ~ e*1
#   alt1_xb ~ f*1
#   alt2_xb ~ f*1
#   alt3_xb ~ f*1
#   
# '
# 
# 
# fit2 <- lavaan(model, data = data_wide, fixed.x=FALSE, ordered=c("size2"))

summary(fit1)

# summary(fit2)


```
Please note that the estimated variance (model implied variance) of the `size` variable is way too large. In reality the variance is `0.35`. This indicates we have a misspecified model. 

## Assignment 7

Unfortunately, in Lavaan it is not implemented to include an interaction term with a latent variable into the structural part of the model. We have to fall back on a two-step approach. For some literature on the differences between a one-step and two-step approach see Anderson and Gerbing (1988).[^4]

[^4]: Anderson, J. C., & Gerbing, D. W. (1988). Structural equation modeling in practice: A review and recommended two-step approach. *Psychological bulletin, 103*(3), 411.

But here it goes...
```{r,  attr.source = '.numberLines', results='hold'}
#credits where credits are due: https://stackoverflow.com/questions/24399353/r-lavaan-coding-latent-variable-interactions

# 1. set up our measurement model
model2 <- '
  #latent variable
  FX =~ 1*alt1_xa
  FX =~ 1*alt2_xa
  FX =~ 1*alt3_xa
  
  FX =~ a*alt1_xb
  FX =~ a*alt2_xb
  FX =~ a*alt3_xb
  
  #variances
  alt1_xa ~~ b*alt1_xa
  alt2_xa ~~ b*alt2_xa
  alt3_xa ~~ b*alt3_xa
  
  alt1_xb ~~ c*alt1_xb
  alt2_xb ~~ c*alt2_xb
  alt3_xb ~~ c*alt3_xb
  
  FX ~~ FX
  '
fit <- lavaan(model2, data = data_wide, missing = "fiml", fixed.x=FALSE)

# 2. extract the predicted values of the cfa and add them to new dataframe data_wide2
data_wide2 <- data.frame(data_wide, predict(fit))

# 3. create a new variable with the interaction of FX and size
data_wide2$FXsize <- data_wide2$FX * data_wide2$size

# 3. now set up the structural model and add the predefined interaction

model2 <- '
  
  FX ~~ FX
  Y1 ~~ Y1
  Y2 ~~ Y2
  size ~~ 0.35*size #I am fixing the variance to the observed variance. 
  FXsize ~~ FXsize
  
  #covariances
  Y1 ~~ Y2
 
  #regression model
  Y1 ~ FX + size + FXsize
  Y1 ~ 1
  FX ~ size
  Y2 ~ FX + size + FXsize
  Y2 ~ 1
   
  
'

fit <- lavaan(model2, data = data_wide2, missing = "fiml", fixed.x=FALSE)
summary(fit)



```
## final model? 

Let us assume that based on the literature, I don't expect that size would lead to my latent variable (e.g. network-happiness). 
I do not expect that people (egos) with larger networks have networks in which the alters are on average happier. Thus I don't want to include this direct path in my model. I also do not expect that network size by itself is related to my happiness. I thus also would like to exclude this path from the model. 
I just have very good reasons (ahum) to think that each alter contributes uniquely to my happiness, there is an additive effect. This implies an interaction between network size and our latent variable. Let us estimate this more 'theoretical' model. 

```{r,  attr.source = '.numberLines', results='hold'}

model <- '
  
  FX ~~ FX
  Y1 ~~ Y1
  Y2 ~~ Y2
  FXsize ~~ FXsize
  
  #covariances
  Y1 ~~ Y2
 
  #regression model
  Y1 ~ FX + FXsize
  Y1 ~ 1
  Y2 ~ FX + FXsize
  Y2 ~ 1
   
  
'

fit <- lavaan(model, data = data_wide2, missing = "fiml", fixed.x=FALSE)
summary(fit)



```

We would conclude that my line of reasoning holds true with respect to Y2 but not with respect to Y1. 

# Alternative Approaches

The above micro-macro models may also be estimated within Mplus developed by Muthén and Muthén [www.statmodel.com]("www.statmodel.com"). If you have Mplus installed on your computer, you may use the R package  `MplusAutomation` to estimate models with Mplus within R. Below you may find two examples with Mplus: one demonstrating the persons as variable approach, the other demonstrating the multi-level approach. 


